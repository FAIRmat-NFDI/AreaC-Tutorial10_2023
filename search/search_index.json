{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>This page contains the documents following the FAIRmat tutorial 10, presented on 14.06.2023 by Luca M. Ghiringhelli, Nathan Daelman, and Jos\u00e9 M. Pizarro. It is divided in five main parts:</p> <ol> <li>Part I: How to explore the NOMAD Archive and Repository.</li> <li>Part II: How to make an upload and query NOMAD.</li> <li>Part III: Numerical precision in ab initio calculations.</li> <li>Part IV: Workflows and how to link DFT and beyond-DFT calculations.</li> <li>Part V: Knowledge-based XC functional exploration.</li> </ol>"},{"location":"part1/","title":"Part I: How to explore the NOMAD Archive and Repository.","text":"<p>This part contains the information on how to explore the NOMAD Archive and Repository (in short, NOMAD-lab) in order to find electronic-structure calculations data. A more general tutorial can be found in the FAIRmat tutorial 1 and the materials therein.</p>"},{"location":"part1/#entries_section","title":"Exploring NOMAD","text":"<p>Go to the NOMAD-lab website. </p> <p>There are two main versions when exploring NOMAD-lab: the stable version (by clicking the \"Open NOMAD\" button) and the Beta or staging version. As the current NOMAD infrastructure is constantly being updated, we recommend you to go to the Beta version. The link can be also found when scrolling down in the main landing page of NOMAD-lab or when clicking on the top menu \"Solutions &gt; NOMAD\" and scrolling down.</p> <p> </p> <p>The landing NOMAD Entries page is a very intuitive and easy-to-use Graphical User Interface (GUI). Here you can explore data according to your preferences by clicking on the filter menus on the left. You can then select a variety of quantities that characterize the Material or system under study, the methodology parameters followed in the calculation or experiment, and the output properties. </p> <p>There is a large variety of options to filter data in NOMAD. In this tutorial, you will learn about data for electronic-structure calculations, i.e., data obtained when solving Density Functional Theory (<code>DFT</code>), <code>GW</code> approximation, Bethe-Salpeter equation (<code>BSE</code>), projected tight-binding models (<code>Projection</code>), and Dynamical Mean-Field Theory (<code>DMFT</code>), as well as in the Properties menu called \"Electronic\". All of these menus contain (meta)information important for these calculations. If you feel some important quantity is missing, or maybe you want to extend to other electronic-structure techniques, please contact us!</p>"},{"location":"part1/#going-beyond-the-gui-the-nomad-metainfo-and-querying-data","title":"Going beyond the GUI: the NOMAD metainfo and querying data","text":"<p>The most important aspect of NOMAD is the metainfo definitions. The whole set of NOMAD metainfo definitions can be found in the top-left menu \"Analyze &gt; The NOMAD Metainfo\". As you can see, not all the quantities and sections appear in the GUI exploration menus, but rather a selected group. In Part II, you will learn how to explore this metainfo for a specific entry.</p> <p>Another important functionality in NOMAD is being able to perform queries and analyze the resulting downloaded data from it. Once you have decided searching for a set of materials with certain properties and derived from your prefered methodology, NOMAD gives you another tool to perform a query via Application Programming Interface (API) queries or calls. This can be found by clicking the symbol <code>&lt;&gt;</code> at the top of the filter menus. In Part II, you will learn how to use an API query to get GW data and work with it in a Jupyter Notebook for analysis and plotting of the DFT and GW band structure.</p>"},{"location":"part2/","title":"Part II: How to make an upload and query data in NOMAD.","text":"<p>This part contains the information on how to make an upload with computational data in NOMAD, how to browse through the parsed metadata, and how to use API calls to query data in NOMAD for analysis. We will use an example dataset for a DFT+GW calculation for Si2. Similar to the Part I, a more general tutorial can be found in the FAIRmat tutorial 1 and the materials therein.</p> <p>You can find this example data by searching certain parameters, as shown at the end of Part I. You can download the example data files when browsing to the specific entry. The upload id of the example used in this tutorial is 9FVTPztzTdGNVSEbc4QbXg.</p>"},{"location":"part2/#uploading-computational-data-to-nomad","title":"Uploading computational data to NOMAD","text":"<p>Go to the NOMAD Entries page, and click on the top-left menu \"Publish &gt; Uploads\". </p> <p>You can then click on \"Create a new upload\" button, or even try one of the examples in \"Add example uploads\". The page for creating a new upload allows you to upload, edit author metadata, and publish your data with an embargo. The system works by a drag-and-drop files system. For this tutorial, you are going to learn how to upload and explore the metadata of a DFT + GW calculation done by the code exciting. </p>"},{"location":"part2/#browsing-entries","title":"Browsing entries","text":"<p>As you can see in the GIF, after we drag-and-drop the zipped files a processing starts. NOMAD will try to find the corresponding parsers, and if succesful, new entries are generated. In this example, you are uploading a DFT + GW calculation for which three entries are generated: <code>DFT SinglePoint</code>, <code>GW SinglePoint</code>, and <code>GW</code>. You can later visit the Part IV to learn more, but for now is enough to know that NOMAD differentiates between the DFT part, the GW part, and then combines both in what is called the <code>GW workflow</code> entry. This last one is the one containing the combined meta-information of DFT and GW, and thus, it is the most general entry of all three.GW upload gi</p> <p>You can browse each entry by clicking on right arrow <code>\u2192</code>. You will land in the Overview page of the entry, which contains basic information and visualizations for the entry.</p> <p>Extra visualizations, such as the Electronic properties or the Workflow graph will appear depending on the character of the entry (for example, a Molecular Dynamics calculation will not contain Electronic properties but rather Thermodynamic properties and Trajectories visualizations, see FAIRmat tutorial 7).</p> <p> </p> <p>Besides Overview, there are also other menus: \"FILES\", a list of all the files present in the entry folder, \"DATA\", the populated metadata sections and quantities, and \"LOGS\", a list of logging success, warnings and errors. In the \"DATA\" menu, you can browse through the specifically populated NOMAD metainfo definitions.</p> <p>A computational data entry in NOMAD will be composed of the following sections:</p> <ol> <li><code>metadata</code>: contains general meta-information about the entry, such as author, upload time, upload id, etc.</li> <li><code>run</code>: contains all the parsed data from a computational simulation. It divided in four main subsections: <code>program</code> which contains meta-information about the program (name, version...), <code>system</code> which contains meta-information about the system or material for which the calculation was performed (atom positions, symmetry...), <code>method</code> which contains meta-information about the input methodological parameters used in the simulation, and <code>calculation</code> which contains all the output quantities.</li> <li><code>workflow2</code>: contains all the information on the workflow, such as tasks, inputs, outputs, etc. You can learn more in detail about it in Part IV.</li> <li><code>results</code>: contains a set of references to <code>run</code> and <code>workflow2</code> that are then shown in the GUI for visualization and exploration purposes.</li> </ol>"},{"location":"part2/#querying-nomad-data","title":"Querying NOMAD data","text":"<p>In this section, you can learn about how to query processed data in NOMAD by using the Jupyter Notebook prepared specifically to find this entry. This can be found here. Select \"FAIRmat Tutorial 10\" and click \"Start\".</p>"},{"location":"part3/","title":"Part III: Numerical precision in ab initio calculations.","text":"<p>In this part, you will learn about several new quantities and tools for working with numerical-precision settings in NOMAD. These tools will help you</p> <ol> <li>query for the level of precision or conformity that you need.</li> <li>deploy extracted data into a notebook to start performing data science.</li> </ol> <p>Note that precision specifies how close a calculation's convergence is with respect to the complete basis set limit, and not necessarily experiments (that would be accuracy). As such, it only really makes sense when comparing entries of the same system. It is best thought of as a filter that gets applied after you have already chosen your material and method of interest.</p> <p>Since these precision quantities are new and by times community-specific, this tutorial places the emphasis on their definitions. By times it also briefly touches on the bare minimum of theoretical knowledge required to handle them, but mostly leaves the interested reader with references to follow up on. There are also a couple of example instructions guiding you to a specific entry or for downloading processed data into a notebook. Lastly, watch out for the boxes with a pencil sign. They delve deeper into some topics and can be skipped at the first reading.</p>"},{"location":"part3/#lay-out-of-the-precision-section","title":"Lay-out of the Precision section","text":"<p>To start, go to the Entries overview page &gt; FILTERS (side menu) &gt; Precision. To navigate to the Entries page, check out Part I - Exploring NOMAD. The side menu in front of you is ordered so it starts out very general (k-line Density, Code-specific Tier) and below the choice of Basis Set, only contains quantities specific to certain basis set types, e.g. Plane-wave Cutoff, APW Cutoff. The same quantities can be found for each entry in their OVERVIEW page &gt; DATA &gt; results &gt; method &gt; simulation &gt; precision. Following along with the example below, make sure your precision settings are sensible by filtering down to a well-defined system (cubic-centered Actinium) via FILTERS &gt; Material &gt; Ac &gt; only compositions that ... &gt; sorting by Formula.</p> <p>Some quantities are so specific and / or verbose, that they are relegated to DATA. This means that they do not show up in the side menu, nor the search bar. Muffin-tin spheres gives an example of when it is interesting to check them out and how to do so.</p>"},{"location":"part3/#k_section","title":"Reciprocal space","text":"<p>In periodic systems, the most universal numerical parameter is the integration of the reciprocal space, or k-space, and its sampling. With the sampling points often being spaced at fixed intervals, one can define a homogeneous k-density \\(= \\frac{\\text{no. k-points}}{||\\text{k-lattice vector}||}\\). Then, as the k-density ramps up, the Bloch wavefunction converges.  Each (periodic) axis has its own k-density, and though one normally tries to keep these constant among them, fluctuations may happen due the discretized nature of the k-point sampling. To ensure that NOMAD users obtain data that meets their convergence needs, k-line density only shows the lowest density value.</p> <p>Many codes only support 3-D unit cells. Any lower-dimensional cases are then handled by introducing a physical separation (vacuum) between the otherwise periodic images, as well as reducing the k-point sampling to a minimum (1 grid point). Such edge cases can cause false positives, i.e. unphysically low k-line densities, given our current definition. NOMAD distinguishes dimensionality in <code>results.material.toplogy.dimensionality</code> and will therefore only provide a k-line density in a true 3-D case. You may also expect lower-dimensional cases to be supported in the near future, where only periodic axes are accounted for.</p> <p> </p> <p>Band structure calculations</p> <p>For their spatial resolution, band structures sample along line paths connecting several high-symmetry points instead of the reciprocal lattice vectors. Not only can each line path can have its own spacing, their projections onto the reciprocal lattice vectors will vary. In short, they deviate from the fixed spacing requirement, and therefore, NOMAD filters them out. Conceptually, this is fine, since k-line density's aim is provide context to convergence, where this type of sampling does not apply.</p>"},{"location":"part3/#elec_section","title":"Electronic Structure","text":"<p>At the level of the unit cell, there are several paradigms on how to represent the electronic wavefunction. In this tutorial, we explore basis sets that start from plane waves, which mathematically mix well with the Bloch convolution. In particular, we address projector-augmented waves (PAW) and augmented plane waves (APW). As their names suggest, both extend the regular plane waves in regions where convergence is slow, namely around atomic nuclei.</p> <p>A big distinction between PAW and APW is where they each draw this divide:</p> <ul> <li>PAW: the deciding factor is the orbital energies, with those below a certain threshold accounted for in special-purpose pseudopotentials.   More on this in Pseudopotentials.</li> <li>APW: here the divide is spatial in nature.   A (mostly) spherical region, i.e. the muffin-tin sphere, is drawn surrounding the nuclei.   The valence electrons reside in interstitial region between these spheres. </li> </ul>"},{"location":"part3/#val_section","title":"Valence Electrons","text":"<p>The main parameter controlling the plane waves is the longest k-vector \\(\\mathbf{G}^{max}\\). A basis set of plane waves is then generated at fixed intervals, i.e. the secondary parameter, up to \\(\\mathbf{G}^{max}\\). Since the sampling is symmetric in each direction, the length, \\(||\\mathbf{G}^{max}||\\), suffices. By convention, most plane wave (especially PAW) codes express the vector length in energy units, which NOMAD reports as plane-wave cutoff, \\(E^{max}_{cut} = \\frac{\\left(\\hbar ||\\mathbf{G}_{cut}^{max}||\\right)^2}{2m_e}\\).</p> <p> </p> <p>In principle, one can follow the same reasoning for the APW paradigm. However, the cutoff energy alone gives an incomplete view. While in PAW the plane waves sample the whole supercell, in APW they are barred from the muffin-tin spheres. The convention here is to compare the length of \\(G^{max}\\) to the largest muffin-tin radius in reciprocal space, yielding the unit-less fraction, APW cutoff, \\(||\\mathbf{R}_{MT}^{min}|| \\cdot ||\\mathbf{G}_{cut}^{max}||\\).</p> <p> </p> <p>NOMAD points out these differences by specifying the unit after the quantity name and between brackets. For more detail, hover over the quantity name.</p> <p>Both cutoff types can safely be increased to retrieve entries with progressively better converged valence electron wavefunctions.</p> <p>What about grid spacing?</p> <p>At the moment, the mesh of the reciprocal or fast Fourier-transformed (FFT) space is not yet extracted. It is on the planned feature list, though with low priority, considering that most of the convergence is already captured by the cutoff. If an upload or analysis ever requires a new feature, feel free to reach out to us via fairmat@physik.hu-berlin.de.</p>"},{"location":"part3/#core-electrons","title":"Core Electrons","text":"<p>The mathematical parameters describing the electronic core region are extracted, but do not appear in the side menu.  To access them, select an entry, e.g. type <code>entry_id = zxhFQjN5Mny1FW5QEOGxWLPThF3r</code> in the search bar &gt; OVERVIEW &gt; DATA. In the DATA browser follow run (all computational data) &gt; method ( metadata describing the calculation setup) &gt; electrons_representation. This sections contains metadata on the mathematical description of the electronic structure.</p> <p>Each representation comes with a scope and a type, which specify the entity (e.g. wavefunction, density, exchange-correlation density, integration grid) and the overall basis set, respectively. Hardly any code sticks to a single set of parameters values, instead adapting them according to task at hand. For this reason there can be multiple electrons representations, each with their unique scope. Those reported in the search are always the settings for <code>scope = wavefunction</code>.</p> <p>As you have learned in Electronic Structure, some basis sets divide the orbital set into widely different approaches. Each basis_set subsection describes and individual region. Here too, you will find scope and type with pretty much the same definitions. Take note though, since the basis set scope refers to the region it encodes. Examples include cases mentioned above, based on</p> <ul> <li>orbital energy: core vs valence.</li> <li>spatial boundaries: muffin-tin vs interstitial</li> <li>Hamiltonian: kinetic and electron-nucleus interaction vs electron-electron interaction in the case of CP2k's Quickstep algorithm.</li> </ul>"},{"location":"part3/#mt_section","title":"Muffin-tin spheres","text":"<p>APW is an all-electron approach, meaning that all orbitals are relaxed during an electronic self-consistent (SCF) routine. By itself, APW is no longer state-of-the-art and has been followed up by extensions such as LAPW, SLAPW, and APW+lo. Throughout this tutorial, the term APW is used as a shorthand for this entire family of approaches, but in this section alone, it will refer to just the progenitor.</p> <p>While a full overview of the theory is beyond the scope of this tutorial, a quick rundown is necessary to explain some of the NOMAD design choices. The muffin-tin potential around the nucleus \\(\\alpha\\) allows the code to fall back on a more simple, spherically symmetric Hamiltonian to solve. The basis set thus consists out of the harmonics \\(Y_L\\left(r_\\alpha\\right)\\) with radially dependent weights \\(u\\left(r_\\alpha, \\epsilon\\right)\\). In the original APW approach, the energy parameter \\(\\epsilon\\) is a variable that should converge to the respective orbital energies. The core states then align with the well-known case of a multi-electron atom system and are tackled separately from the valence states. 1</p> <p>The muffin-tin valence bands, meanwhile, have to match with their plane-wave counterparts at the boundary. While this formulation of APW is complete, it leads to a set of non-linear equations. More modern implementations linearize these equations by freezing the energy parameter \\(\\epsilon_{l,\\alpha}\\) by nucleus and harmonic index \\(l\\). 1 2 Obviously, a single \\(\\epsilon_{l,\\alpha}\\) value per \\(l\\)-channel cannot account for dispersion and (anti-)bonding effects, unless they match the state energy perfectly. Instead, corrections are worked in by adding higher-order derivatives of \\(u\\left(r_\\alpha, \\epsilon\\right)\\) to the basis set. Likewise, each derivative order must also match up at the boundary. If the corrections run up to first-order, the approach is called LAPW, else SLAPW for those beyond.</p> <p>Another effect of constraining the energy parameter \\(\\epsilon\\) to \\(l\\), is that it cannot account for wavefunctions with different nodes or main quantum numbers \\(n\\). Some core states, however, are too high-energy to be well-contained within their muffin-tin spheres. They are typically referred to as semicore and have to be treated as valence states. The preferred way to tackle them, is by adding an additional wavefunction, similar to LAPW or SLAPW, but with a normalization requirements in lieu of some boundary constraints. These are called local orbitals (lo) and can be freely added by the user to supplement APW or LAPW. By no means are they restricted to describing semicore states, but can also tackle additional unoccupied states (used in beyond-DFT) as well.</p> <p> </p> <p>While some APW codes require a manual setup for each orbital, e.g. Wien2k, others use a couple of \"steering\" parameters to generate the orbitals. In NOMAD, we typically to keep parameters as concise as possible, though in this case this is not practical for two reasons:</p> <ol> <li>There is no consensus on which steering parameters to use. Each code allows different levels of customization.</li> <li>The energy parameters provided by the user should not be directly used in the SCF routines.    Rather, the code will have some algorithm that optimizes the initial energy parameters based on the geometry.    As such, any orbital degeneracy is lifted.</li> </ol> <p>To capture the orbitals states completely, NOMAD instead \"unrolls\" the steering parameters down to individual radial valence orbitals, identified by their type (e.g. APW, LAPW, lo), associated harmonic index \\(l\\), derivative order of \\(u\\left( r \\right)\\), and of course, the initial energy parameter guess. The sampling grid inside the muffin-tin region, as well as the treatment of the core electrons are all specified at the basis set level.</p> <p>Uploading the right files</p> <p>Most APW codes leave the orbital specification out of their main input file. Similarly, they will also write out their actual initial guesses for the energy parameters out to another intermediate file. If you want NOMAD to pick up on these parameters, please include the files in the table below into your upload. They are automatically generated, so there are no extra steps involved.</p> code name file name exciting <code>&lt;species&gt;.xml</code> fleur <code>out.xml</code> (the main output file) Wien2k <code>&lt;calculation&gt;.inc1</code> Elk Not supported yet"},{"location":"part3/#pseudo_section","title":"Pseudopotentials","text":"<p>With the exception of APW, most plane wave codes hide the core structure via an effective potential for the valence electrons. Where most of these older pseudopotentials where constrained in their range of applications, those built for projector-augmented waves exhibit the highest degree of flexibility.</p> <p>Where before NOMAD would simply indicate the usage of pseudopotentials, it now gives a more complete description, such as: the title, the density functional (or sometimes GW) used to generate the pseudopotential, projector information, the recommended minimum plane wave cutoff to be used for the valence electrons, and whether or not it is norm-conserving. The latter is a useful (but more expensive) integration property and is a prerequisite for some methods.  To try this out for yourself, look up <code>entry_id = zz7J6c9cn_K5B4Ecbiasy4xQ-hYl</code> and navigate to OVERVIEW &gt; DATA &gt; run &gt; method &gt; atom_parameters (describes the calculation setup by elemental type) &gt; pseudopotential.</p> <p>Why am I seeing double quantities?</p> <p>The NOMAD metainfo is semantically constructed. Consequentially, a quantity may belong under several categories. In this case, they always share the same name and definition though. Meanwhile, some quantities (e.g. pseudopotential vs pseudopotential_name) may appear to be similar, but are not exactly identical. Likely, one of them is legacy (pseudopotential_name). The legacy quantity will then be deprecated, though their actual removal may be scheduled later for compatibility reasons.</p> <p>Disclaimer</p> <p>At the moment, parsing is restricted to VASP pseudopotentials, including non-standard or self-made versions. Wider code-support is being built out. NOMAD takes great care in complying with the copyright of the standard POTCAR files and their distribution, so all instances are stripped down to their metadata alone.</p>"},{"location":"part3/#tier_section","title":"Code-specific tiers","text":"<p>Filtering for the aforementioned quantities requires quite some expertise, and it is hard often to weigh the significance of two parameters in the electronic convergence. Some codes have benchmarked their own suggested settings into a list of increasing precision, i.e. tiers. Tiers provide the user base with a relatively safe reference, without having to run any benchmarks themselves. Consequentially, they facilitate standardization and interoperability among users and / or publications. Typically, lower tiers are used to save on resources when exploring large materials' spaces and running large or long simulations. They can also act as starting points for higher tiers that provide high-quality data.</p> <p>Essentially, these tiers hide the high-dimensional parameter values behind a set of hierarchical categories. One such good example of this complexity can be found in <code>entry_id = z-wO_IzCW9sDvysmF500duxvDXDs</code>. The section <code>run.method.electrons_representation</code> contains the corresponding settings. To view all quantities, including those unique to the code, select code specific in the upper-right corner. These are hidden by default.</p> <p>Back in the Entries overview page, you can filter by tier by typing <code>&lt;code name&gt; - &lt;tier name&gt;</code> (e.g. <code>VASP - accurate</code>) into the NOMAD side menu &gt; Precision &gt; Code-specific Tier. <code>&lt;code name&gt;</code> is integral to the format, because tiers are code-specific. This quantity is not meant to provide some kind of comparison across codes. <code>&lt;tier name&gt;</code>, meanwhile, is case-sensitive, but suggestions will pop up once you start typing.</p> <p>Overall, Code-specific tier captures a lot of complexity at once, making it great for quick searches. Beware though: it is also very picky, and will strongly reduce the number of entries returned.</p> <p>Tier matching</p> <p>Contrary to other precision quantities like k-line density, plane-wave cutoff, or APW cutoff, tiers are discrete, not continuous. Settings between two tiers are hard to pin down, even qualitatively, since the setting parameters have differing weights. Therefore, NOMAD only assigns perfect matches. When even one value in the settings is altered by the user, the calculation is immediately disqualified from the tier. This does not mean that the data is invalid or less valuable, though, just that it will be not show up when the filter is applied.</p> <ol> <li> <p>Andris Gulans, Stefan Kontur, Christian Meisenbichler, Dmitrii Nabok, Pasquale Pavone, Santiago Rigamonti, Stephan Sagmeister, Ute Werner, and Claudia Draxl. Exciting: a full-potential all-electron package implementing density-functional theory and many-body perturbation theory. J. Phys.: Condens. Matter, 26(36):363202, September 2014. URL: https://iopscience.iop.org/article/10.1088/0953-8984/26/36/363202 (visited on 2023-04-26), doi:10.1088/0953-8984/26/36/363202.\u00a0\u21a9\u21a9</p> </li> <li> <p>David J. Singh and Lars Nordstr\u00f6m. Planewaves, pseudopotentials, and the LAPW method. Springer, New York, NY, 2nd ed edition, 2006. ISBN 978-0-387-28780-5 978-0-387-29684-5.\u00a0\u21a9</p> </li> </ol>"},{"location":"part4/","title":"Part IV: Workflows and how to link DFT and beyond-DFT calculations.","text":"<p>This part contains the basic knowledge on understanding and learning to use NOMAD workflows, and its relation with DFT and beyond-DFT (GW, BSE, DMFT, etc.) methodologies. You will use a ficticious example of a simulation workflow, where the files and folder structure is: <pre><code>.\n\u251c\u2500\u2500 pressure1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 temperature1\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 dmft_p1_t1.hdf5\n\u2502\u00a0\u00a0 \u2502   \u2514\u2500\u2500 ...extra auxiliary files\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 temperature2\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 dmft_p1_t2.hdf5\n\u2502\u00a0\u00a0 \u2502   \u2514\u2500\u2500 ...extra auxiliary files\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dft_p1.xml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 tb_p1.wout\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...extra auxiliary files\n\u2514\u2500\u2500 pressure2\n \u00a0\u00a0 \u251c\u2500\u2500 temperature1\n \u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 dmft_p2_t1.hdf5\n \u00a0\u00a0 \u2502   \u2514\u2500\u2500 ...extra auxiliary files\n \u00a0\u00a0 \u251c\u2500\u2500 temperature2\n \u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 dmft_p2_t2.hdf5\n \u00a0\u00a0 \u2502   \u2514\u2500\u2500 ...extra auxiliary files\n \u00a0\u00a0 \u251c\u2500\u2500 dft_p2.xml\n \u00a0\u00a0 \u251c\u2500\u2500 tb_p2.wout\n \u00a0\u00a0 \u2514\u2500\u2500 ...extra auxiliary files\n</code></pre> Each of the mainfiles represent an electronic-structure calculation (either DFT, TB, or DMFT) which in turn is then parsed into a singular entry in NOMAD. When dragged into the NOMAD Upload page, these files should generate 8 entries in total. This folder structure presents a typical workflow calculation which can be represented as a provenance graph: <pre><code>graph LR;\n    A2((Inputs)) --&gt; B2[DFT];\n    A1((Inputs)) --&gt; B1[DFT];\n    subgraph pressure P&lt;sub&gt;2&lt;/sub&gt;\n    B2[DFT] --&gt; C2[TB];\n    C2[TB] --&gt; D21[DMFT at T&lt;sub&gt;1&lt;/sub&gt;];\n    C2[TB] --&gt; D22[DMFT at T&lt;sub&gt;2&lt;/sub&gt;];\n    end\n    D21[DMFT at T&lt;sub&gt;1&lt;/sub&gt;] --&gt; E21([Output calculation P&lt;sub&gt;2&lt;/sub&gt;, T&lt;sub&gt;1&lt;/sub&gt;])\n    D22[DMFT at T&lt;sub&gt;2&lt;/sub&gt;] --&gt; E22([Output calculation P&lt;sub&gt;2&lt;/sub&gt;, T&lt;sub&gt;2&lt;/sub&gt;])\n    subgraph pressure P&lt;sub&gt;1&lt;/sub&gt;\n    B1[DFT] --&gt; C1[TB];\n    C1[TB] --&gt; D11[DMFT at T&lt;sub&gt;1&lt;/sub&gt;];\n    C1[TB] --&gt; D12[DMFT at T&lt;sub&gt;2&lt;/sub&gt;];\n    end\n    D11[DMFT at T&lt;sub&gt;1&lt;/sub&gt;] --&gt; E11([Output calculation P&lt;sub&gt;1&lt;/sub&gt;, T&lt;sub&gt;1&lt;/sub&gt;])\n    D12[DMFT at T&lt;sub&gt;2&lt;/sub&gt;] --&gt; E12([Output calculation P&lt;sub&gt;1&lt;/sub&gt;, T&lt;sub&gt;2&lt;/sub&gt;])</code></pre> Here, \"Input\" refers to the all input information given to perform the calculation (e.g., atom positions, model parameters, experimental initial conditions, etc.). \"DFT\", \"TB\" and \"DMFT\" refer to individual tasks of the workflow, which each correspond to a SinglePoint entry in NOMAD. \"Output calculation\" refers to the output data of each of the final DMFT tasks.</p> <p>The goal of this part is to set up the following workflows:</p> <ol> <li>A <code>SinglePoint</code> workflow for one of the calculations (e.g., the DFT one) in the <code>pressure1</code> subfolder.</li> <li>An overarching workflow entry for each pressure Pi=1,2, grouping all <code>SinglePoint</code> \"DFT\", \"TB\", \"DMFT at T1\", and \"DMFT at T2\" tasks.</li> <li>A top level workflow entry, grouping together all pressure calculations.</li> </ol> <p>The files for all these cases can be found in Workflow YAML files. You can try writing these files yourself first, and then compare them with the tested files.</p>"},{"location":"part4/#starting-example-singlepoint-workflow","title":"Starting example: SinglePoint workflow","text":"<p>NOMAD is able to recognize certain workflows in an automatic way, such as the <code>SinglePoint</code> case mentioned above. However, to showcase how to the use workflows in NOMAD, you will learn how to \"manually\" construct the SinglePoint workflow, represented by the following provenance graph: <pre><code>graph LR;\n    A((Inputs)) --&gt; B[DFT];\n    B[DFT] --&gt; C([Output calculation]);</code></pre> To define a workflow manually in NOMAD, you must add a YAML file to the upload folder that contains the relevant input, output, and task information. This file should be named <code>&lt;filename&gt;.archive.yaml</code>. In this case, you should include the file <code>single_point.archive.yaml</code> with the following content:</p> <pre><code>workflow2:\nname: SinglePoint\ninputs:\n- name: Input structure\nsection: '../upload/archive/mainfile/pressure1/dft_p1.xml#/run/0/system/-1'\noutputs:\n- name: Output calculation\nsection: '../upload/archive/mainfile/pressure1/dft_p1.xml#/run/0/calculation/-1'\ntasks:\n- m_def: nomad.datamodel.metainfo.workflow.TaskReference\ntask: '../upload/archive/mainfile/pressure1/dft_p1.xml#/workflow2'\nname: DFT at Pressure P1\ninputs:\n- name: Input structure\nsection: '../upload/archive/mainfile/pressure1/dft_p1.xml#/run/0/system/-1'\noutputs:\n- name: Output calculation\nsection: '../upload/archive/mainfile/pressure1/dft_p1.xml#/run/0/calculation/-1'\n</code></pre> <p>Note several things about the content of this file:</p> <ol> <li><code>name</code> keys are optional.</li> <li>The root path of the upload can be referenced with <code>../upload/archive/mainfile/</code>. Starting from there, the original directory tree structure of the upload is maintained.</li> <li><code>inputs</code> reference the section containing inputs of the whole workflow. In this case this is the section <code>run[0].system[-1]</code> parsed from the mainfile in the path <code>pressure1/dft_p1.xml</code>.</li> <li><code>outputs</code> reference the section containing outputs of the whole workflow. In this case this is the section <code>run[0].calculation[-1]</code> parsed from the mainfile in the path <code>pressure1/dft_p1.xml</code>.</li> <li><code>tasks</code> reference the section containing tasks of each step in the workflow. These must also contain <code>inputs</code> and <code>outputs</code> properly referencing the corresponding sections; this will then link inputs/outputs/tasks in the NOMAD Archive. In this case this is a <code>TaskReference</code> to the section <code>workflow2</code> parsed from the mainfile in the path <code>pressure1/dft_p1.xml</code>.</li> <li><code>section</code> reference to the uploaded mainfile specific section. The left side of the <code>#</code> symbol contains the path to the mainfile, while the right contains the path to the section.</li> </ol> <p>This will produce an extra entry with the following Overview content:</p> <p>Note that you are referencing sections which are lists. Thus, in each case you should be careful to reference the correct section for inputs and outputs (example: a <code>GeometryOptimization</code> workflow calculation will have the \"Input structure\" as <code>run[0].system[0]</code>, while the \"Output calculation\" would also contain <code>run[0].system[-1]</code>, and all intermediate steps must input/output the corresponding section system).</p> <p>NOMAD workflow filename</p> <p>The NOMAD workflow YAML file name, i.e., <code>&lt;filename&gt;</code> in the explanation above, can be any custom name defined by the user, but the file must keep the extension <code>.archive.yaml</code> at the end. This is done in order for NOMAD to recognize this file as a custom schema. Custom schemas are widely used in experimental parsing, and you can learn more about them in the FAIRmat tutorial 8.</p> <p>You can extend the workflow meta-information by adding the metholodogical input parameters. These are stored in NOMAD in the section path <code>run[0].method[-1]</code>. The new <code>single_point.archive.yaml</code> will be:</p> <pre><code>workflow2:\nname: SinglePoint\ninputs:\n- name: Input structure\nsection: '../upload/archive/mainfile/pressure1/dft_p1.xml#/run/0/system/-1'\n- name: Input methodology parameters\nsection: '../upload/archive/mainfile/pressure1/dft_p1.xml#/run/0/method/-1'\noutputs:\n- name: Output calculation\nsection: '../upload/archive/mainfile/pressure1/dft_p1.xml#/run/0/calculation/-1'\ntasks:\n- m_def: nomad.datamodel.metainfo.workflow.TaskReference\ntask: '../upload/archive/mainfile/pressure1/dft_p1.xml#/workflow2'\nname: DFT at Pressure P1\ninputs:\n- name: Input structure\nsection: '../upload/archive/mainfile/pressure1/dft_p1.xml#/run/0/system/-1'\n- name: Input methodology parameters\nsection: '../upload/archive/mainfile/pressure1/dft_p1.xml#/run/0/method/-1'\noutputs:\n- name: Output calculation\nsection: '../upload/archive/mainfile/pressure1/dft_p1.xml#/run/0/calculation/-1'\n</code></pre> <p>which in turn produces a similar workflow than before, but with an extra input node:</p>"},{"location":"part4/#pressure-workflows","title":"Pressure workflows","text":"<p>Now that you know the basics of the workflow YAML schema, let's try to define an overarching workflow for each of the pressures. For this section, you will learn how to create the workflow YAML schema for the P1 case; the extension for P2 is then a matter of changing names and paths in the YAML files. For simplicity, you can skip referencing to methodologies.</p> <p>Thus, the <code>inputs</code> can be defined as: <pre><code>workflow2:\nname: DFT+TB+DMFT at P1\ninputs:\n- name: Input structure\nsection: '../upload/archive/mainfile/pressure1/dft_p1.xml#/run/0/system/-1'\n</code></pre> and there are two <code>outputs</code>, one for each of the DMFT calculations at distinct temperatures: <pre><code>  outputs:\n- name: Output DMFT at P1, T1 calculation\nsection: '../upload/archive/mainfile/pressure1/temperature1/dmft_p1_t1.hdf5#/run/0/calculation/-1'\n- name: Output DMFT at P1, T2 calculation\nsection: '../upload/archive/mainfile/pressure1/temperature2/dmft_p1_t2.hdf5#/run/0/calculation/-1'\n</code></pre> Now, <code>tasks</code> are defined for each of the methodologies performed (each corresponding to an underlying SinglePoint workflow). To define a valid workflow, each task must contain an input that corresponds to one of the outputs of the previous task. Moreover, the first task should take as input the overall input of the workflow, and the final task should also have as an output the overall workflow output. Then: <pre><code>  tasks:\n- m_def: nomad.datamodel.metainfo.workflow.TaskReference\ntask: '../upload/archive/mainfile/pressure1/dft_p1.xml#/workflow2'\nname: DFT at P1\ninputs:\n- name: Input structure\nsection: '../upload/archive/mainfile/pressure1/dft_p1.xml#/run/0/system/-1'\noutputs:\n- name: Output DFT at P1 calculation\nsection: '../upload/archive/mainfile/pressure1/dft_p1.xml#/run/0/calculation/-1'\n- m_def: nomad.datamodel.metainfo.workflow.TaskReference\ntask: '../upload/archive/mainfile/pressure1/tb_p1.wout#/workflow2'\nname: TB at P1\ninputs:\n- name: Input DFT at P1 calculation\nsection: '../upload/archive/mainfile/pressure1/dft_p1.xml#/run/0/calculation/-1'\noutputs:\n- name: Output TB at P1 calculation\nsection: '../upload/archive/mainfile/pressure1/tb_p1.wout#/run/0/calculation/-1'\n- m_def: nomad.datamodel.metainfo.workflow.TaskReference\ntask: '../upload/archive/mainfile/pressure1/temperature1/dmft_p1_t1.hdf5#/workflow2'\nname: DMFT at P1 and T1\ninputs:\n- name: Input TB at P1 calculation\nsection: '../upload/archive/mainfile/pressure1/tb_p1.wout#/run/0/calculation/-1'\noutputs:\n- name: Output DMFT at P1, T1 calculation\nsection: '../upload/archive/mainfile/pressure1/temperature1/dmft_p1_t1.hdf5#/run/0/calculation/-1'\n- m_def: nomad.datamodel.metainfo.workflow.TaskReference\ntask: '../upload/archive/mainfile/pressure1/temperature1/dmft_p1_t1.hdf5#/workflow2'\nname: DMFT at P1 and T2\ninputs:\n- name: Input TB at P1 calculation\nsection: '../upload/archive/mainfile/pressure1/tb_p1.wout#/run/0/calculation/-1'\noutputs:\n- name: Output DMFT at P1, T2 calculation\nsection: '../upload/archive/mainfile/pressure1/temperature2/dmft_p1_t2.hdf5#/run/0/calculation/-1'\n</code></pre> Note here:</p> <ul> <li>The <code>inputs</code> for each subsequent step are the <code>outputs</code> of the previous step.</li> <li>The final two <code>outputs</code> coincide with the <code>workflow2</code> <code>outputs</code>.</li> </ul> <p>This workflow (<code>pressure1.archive.yaml</code>) file will then produce an entry with the following Overview page:</p> <p>Similarly, for P2 you can upload a new <code>pressure2.archive.yaml</code> file with the same content, except when substituting 'pressure1' and 'p1' by their counterparts. This will produce a similar graph than the one showed before but for \"P2\".</p>"},{"location":"part4/#the-top-level-workflow","title":"The top-level workflow","text":"<p>After adding the workflow YAML files, Your upload folder directory now looks like: <pre><code>.\n\u251c\u2500\u2500 pressure1\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 dmft_p1_t1.hdf5\n\u2502\u00a0\u00a0 \u2502   \u2514\u2500\u2500 ...extra auxiliary files\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 temperature2\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 dmft_p1_t2.hdf5\n\u2502\u00a0\u00a0 \u2502   \u2514\u2500\u2500 ...extra auxiliary files\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dft_p1.xml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 tb_p1.wout\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...extra auxiliary files\n\u251c\u2500\u2500 pressure1.archive.yaml\n\u251c\u2500\u2500 pressure2\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 temperature1\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 dmft_p2_t1.hdf5\n\u2502\u00a0\u00a0 \u2502   \u2514\u2500\u2500 ...extra auxiliary files\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 temperature2\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 dmft_p2_t2.hdf5\n\u2502\u00a0\u00a0 \u2502   \u2514\u2500\u2500 ...extra auxiliary files\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dft_p2.xml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 tb_p2.wout\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...extra auxiliary files\n\u251c\u2500\u2500 pressure2.archive.yaml\n\u2514\u2500\u2500 single_point.archive.yaml\n</code></pre> In order to define the general workflow that groups all pressure calculations, YOU can reference directly the previous <code>pressureX.archive.yaml</code> files as tasks. Still, <code>inputs</code> and <code>outputs</code> must be referenced to their corresponding mainfile and section paths.</p> <p>Create a new <code>fullworkflow.archive.yaml</code> file with the <code>inputs</code>: <pre><code>workflow2:\nname: Full calculation at different pressures for SrVO3\ninputs:\n- name: Input structure at P1\nsection: '../upload/archive/mainfile/pressure1/dft_p1.xml#/run/0/system/-1'\n- name: Input structure at P2\nsection: '../upload/archive/mainfile/pressure2/dft_p2.xml#/run/0/system/-1'\n</code></pre> And <code>outputs</code>: <pre><code>  outputs:\n- name: Output DMFT at P1, T1 calculation\nsection: '../upload/archive/mainfile/pressure1/temperature1/dmft_p1_t1.hdf5#/run/0/calculation/-1'\n- name: Output DMFT at P1, T2 calculation\nsection: '../upload/archive/mainfile/pressure1/temperature2/dmft_p1_t2.hdf5#/run/0/calculation/-1'\n- name: Output DMFT at P2, T1 calculation\nsection: '../upload/archive/mainfile/pressure2/temperature1/dmft_p2_t1.hdf5#/run/0/calculation/-1'\n- name: Output DMFT at P2, T2 calculation\nsection: '../upload/archive/mainfile/pressure2/temperature2/dmft_p2_t2.hdf5#/run/0/calculation/-1'\n</code></pre> Finally, <code>tasks</code> references the previous YAML schemas as follows: <pre><code>  tasks:\n- m_def: nomad.datamodel.metainfo.workflow.TaskReference\ntask: '../upload/archive/mainfile/pressure1.archive.yaml#/workflow2'\nname: DFT+TB+DMFT at P1\ninputs:\n- name: Input structure at P1\nsection: '../upload/archive/mainfile/pressure1/dft_p1.xml#/run/0/system/-1'\noutputs:\n- name: Output DMFT at P1, T1 calculation\nsection: '../upload/archive/mainfile/pressure1/temperature1/dmft_p1_t1.hdf5#/run/0/calculation/-1'\n- name: Output DMFT at P1, T2 calculation\nsection: '../upload/archive/mainfile/pressure1/temperature2/dmft_p1_t2.hdf5#/run/0/calculation/-1'\n- m_def: nomad.datamodel.metainfo.workflow.TaskReference\ntask: '../upload/archive/mainfile/pressure2.archive.yaml#/workflow2'\nname: DFT+TB+DMFT at P2\ninputs:\n- name: Input structure at P2\nsection: '../upload/archive/mainfile/pressure2/dft_p2.xml#/run/0/system/-1'\noutputs:\n- name: Output DMFT at P2, T1 calculation\nsection: '../upload/archive/mainfile/pressure2/temperature1/dmft_p2_t1.hdf5#/run/0/calculation/-1'\n- name: Output DMFT at P2, T2 calculation\nsection: '../upload/archive/mainfile/pressure2/temperature2/dmft_p2_t2.hdf5#/run/0/calculation/-1'\n</code></pre></p> <p>This will produce the following entry and its Overview page:</p>"},{"location":"part4/#automatic-workflows","title":"Automatic workflows","text":"<p>There are some cases where the NOMAD infrastructure is able to recognize certain workflows automatically when processing the uploaded files. The simplest example is any <code>SinglePoint</code> calculation, as explained above. Other examples include <code>GeometryOptimization</code>, <code>Phonons</code>, <code>GW</code>, and <code>MolecularDynamics</code>. Automated workflow detection may require your folder structure to fulfill certain conditions.</p> <p>Here are some general guidelines for preparing your upload folder in order to make it easier for the automatic workflow recognition to work:</p> <ul> <li>Always organize your files in an top-down structure, i.e., the initial tasks should be upper in the directory tree, while the later tasks lower on it.</li> <li>Avoid having to go up and down between folders if some properties are derived between these files. These situations are very complicated to predict for the current NOMAD infrastructure.</li> <li>Avoid duplication of files in subfolders. If initially you do a calculation A from which a later calculation B is derived and you want to store B in a subfolder, there is no need to copy the A files inside the subfolder B.</li> </ul> <p>The folder structure used throughout this part is a good example of a clean upload which is friendly and easy to work with when defining NOMAD workflows. Another example can be found in Part II, when you learned how to upload a DFT + GW calculation for bulk Si2. In this case, an automatic GW workflow entry was generated.</p>"},{"location":"part5/","title":"Part V: Knowledge-based XC functional exploration","text":"<p>This section was presented as a slide presentation. The PDF version is accessible at  the tutorial's material page.</p>"}]}